{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import the Tensorflow Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BJideTzRDFbw",
    "outputId": "4f772950-73c5-436f-fd03-ff35a89fbd69"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "# UNCOMMENT below lines to use GPUs or COMMENT below lines if you want to use cpu only\n",
    "# if device_name != '/device:GPU:0':\n",
    "#   raise SystemError('GPU device not found')\n",
    "# print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXQ44_4ypil2"
   },
   "outputs": [],
   "source": [
    "import dill #library to store/restore the jupyter session\n",
    "from numpy.random import seed\n",
    "# seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "# set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sojGt84CH1Ju"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NW5hKpauDHtS"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.stats import randint\n",
    "import pandas as pd # data processing, .csv file i/o\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "import seaborn as sns # used for plot interactive graph. \n",
    "from sklearn.metrics import mean_squared_error,r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Import Deeplearning Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout # regulariser\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam as adam\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the filtered time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Axli83h4IF-_"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./dataset/new_1yr_Nan.csv',\n",
    "                 parse_dates={'dtx' : ['ds']}, infer_datetime_format=True, \n",
    "                 low_memory=False, na_values=['NaN','?'], index_col='dtx').interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "GqRkMBIYvdV7",
    "outputId": "66b2a708-7d20-40ce-c5c8-2ff04d400931"
   },
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)\n",
    "# data = data[['dtx','Series','Value']]\n",
    "data = data[['dtx','y']]\n",
    "data.columns = ['dt','y']\n",
    "data['date'] = data['dt'].dt.date\n",
    "data.set_index('dt',inplace = True)\n",
    "# data = data[ data['Series'] == 'current'][['y','date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the prediction timeseries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bSNBuNGYgKUt"
   },
   "outputs": [],
   "source": [
    "last_week_df = pd.read_csv('./dataset/lastweek_opm.csv',sep = ';',low_memory=False,na_values=['NaN','?']).dropna()\n",
    "# # convert the time back into the UK time \n",
    "# # COMMENT the below line if the time is already in UK timezone\n",
    "last_week_df['Time'] = pd.to_datetime(last_week_df['Time'].astype(str).str[:-6]).sub(timedelta(minutes = 330))\n",
    "# # UNCOMMENT the below line if the above linke is commented\n",
    "# last_week_df['Time'] = pd.to_datetime(last_week_df['Time'])\n",
    "week1 = last_week_df[ last_week_df['Series'] == '1w' ]\n",
    "week2 = last_week_df[ last_week_df['Series'] == '2w' ]\n",
    "curr = last_week_df[ last_week_df['Series'] == 'current' ][['Time','Value']]\n",
    "curr.columns = ['dtx','y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_six = time(6,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter the Order Delievery Time Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week1['clean'] = week1['Time'].dt.time.apply(lambda x : x <= time_six ) \n",
    "week2['clean'] = week2['Time'].dt.time.apply(lambda x : x <= time_six ) \n",
    "curr['clean'] = curr['dtx'].dt.time.apply(lambda x : x <= time_six ) \n",
    "curr.loc[curr['clean'], 'y'] = np.nan\n",
    "week1.loc[week1['clean'], 'Value'] = np.nan\n",
    "week2.loc[week2['clean'], 'Value'] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do a linear interpolation on the filtered out time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = curr.interpolate()\n",
    "week1 = week1.interpolate()\n",
    "week2 = week2.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "P6-1PSzq5whw",
    "outputId": "1fcb457b-e23c-4f4e-fad4-9b306820a1a0"
   },
   "outputs": [],
   "source": [
    "test_data = curr.copy().set_index('dtx')[['y']]\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DaHMUHZB-6Lk"
   },
   "outputs": [],
   "source": [
    "# # test_data = test_data[ test_data['Series'] == 'current'] [['Value']]\n",
    "# test_data.reset_index(inplace = True)\n",
    "# test_data['date'] = test_data['dtx'].dt.date\n",
    "# test_data['holiday'] = test_data['date'].apply(lambda x : 1 if x in holiday_df.dt else 0)\n",
    "# test_data.set_index('dtx',inplace = True)\n",
    "# test_data = test_data[['y','holiday']]\n",
    "# # test_data.columns = ['y','holiday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "dp5Uc4hzrLFr",
    "outputId": "808d43ec-9df1-4ef9-f73a-5b4c3ca6ac11",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.plot(data[:6000].reset_index()['dt'],data[:6000]['y'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wKSzl1ZMIXMM"
   },
   "outputs": [],
   "source": [
    "test_data = test_data.reset_index()[['dtx','y']] #,'holiday']]\n",
    "test_data.columns = ['dt','y']#,'holiday']\n",
    "# test_data.set_index('dt',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "2Mx1q6Iw9yNA",
    "outputId": "db41e999-d268-4ddf-e7d6-70a287844652"
   },
   "outputs": [],
   "source": [
    "test_datax = test_data.copy()\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXO76BzPIqmj"
   },
   "outputs": [],
   "source": [
    "# data.plot(x = 'Value')\n",
    "datax = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yI_Z_bUjscn"
   },
   "outputs": [],
   "source": [
    "# def num_to_word(num):\n",
    "#     word = ['zero',\t'one','two','three','four','five','six','seven','eight','nine','ten','eleven','twelve','thirteen','fourteen','fifteen','sixteen','seventeen','eighteen','nineteen','twenty','twenty-one','twenty-two','twenty-three','twenty-four']\n",
    "#     return word[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9D_I-6NJIyXy"
   },
   "outputs": [],
   "source": [
    "# def extract_feat(df,label = 'ds'):\n",
    "#     cdf = df\n",
    "# #     cdf['date'] = df['ds'].dt.date\n",
    "# #     cdf['hour'] = np.vectorize(num_to_word)(list(df[label].dt.hour))\n",
    "# #     cdf['dayofweek'] = df[label].dt.weekday_name\n",
    "# #     cdf['quarter'] = df[label].dt.quarter\n",
    "#     cdf['month'] = df[label].dt.month_name()\n",
    "# #     cdf['year'] = df[label].dt.year\n",
    "# #     cdf['dayofyear'] = df[label].dt.dayofyear\n",
    "# #     cdf['dayofmonth'] = df[label].dt.day\n",
    "# #     cdf['weekofyear'] = df[label].dt.weekofyear\n",
    "# #     return cdf[['hour','dayofweek','quarter','month','year','dayofyear','dayofmonth','weekofyear']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVRpJfLdI2Xj"
   },
   "outputs": [],
   "source": [
    "# extract_feat( datax, label = 'dt' )\n",
    "# extract_feat( test_datax, label = 'dt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jXc8Yf7MiJD2"
   },
   "outputs": [],
   "source": [
    "# ohe_datax = pd.get_dummies(datax)\n",
    "# ohe_test_datax = pd.get_dummies( test_datax )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_datax = datax.copy()\n",
    "ohe_test_datax = test_datax.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_datax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DMo2hUrcyQgM"
   },
   "outputs": [],
   "source": [
    "# month_list = ['January', 'February', 'March', 'April', 'May', 'June', 'July','August', 'September', 'October', 'November', 'December']\n",
    "# month_list = [ 'month_%s'%s for s in month_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cEejvmcrxNTb"
   },
   "outputs": [],
   "source": [
    "# col_list = ['dt','y','holiday']+month_list\n",
    "# ohe_datax = ohe_datax[col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "RDlQzFFjJBqj",
    "outputId": "5ba10afa-8306-4d41-8e28-3f45f120d073"
   },
   "outputs": [],
   "source": [
    "# print(ohe_test_datax.columns)\n",
    "# month_not_available = [ month for month in month_list if month not in ohe_test_datax.columns ]\n",
    "# # month_not_available\n",
    "# for month in month_not_available: \n",
    "#     ohe_test_datax[month] = 0\n",
    "# ohe_test_datax =  ohe_test_datax[col_list] # test and training data should have same feature list\n",
    "# print(ohe_test_datax.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWl6yNClJSOD"
   },
   "outputs": [],
   "source": [
    "clean_data = ohe_datax.set_index('dt')[['y']]  .interpolate()\n",
    "clean_test_data = ohe_test_datax.set_index('dt')[['y']] .interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1vAb6MdJSFq"
   },
   "outputs": [],
   "source": [
    "resampled_data_test = clean_test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXpHfQgiKYnF"
   },
   "outputs": [],
   "source": [
    "# Inspired from https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True,target_label = None):\n",
    "    n_vars = 1 #if type(data) is list else data.shape[1]\n",
    "    if target_label == None:\n",
    "        dff = pd.DataFrame(data) # not required for our case as the data is already a data frame\n",
    "        target_label = 'var'\n",
    "    else:\n",
    "        dff  = data[[target_label]]\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(dff.shift(i))\n",
    "        names += [ '%s(t-%d)' %(target_label,  i) ]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(dff.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('%s(t)' % (target_label))]\n",
    "        else:\n",
    "            names += [('%s(t+%d)' % (target_label, i))]\n",
    "    return (cols,names)\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZTXOi2HdLPEI",
    "outputId": "9b93fc34-0bdf-4f05-df5d-4e349a1380f4"
   },
   "outputs": [],
   "source": [
    "\n",
    "resampled_data = clean_data.copy()\n",
    "resampled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H3rDtj6m86xf"
   },
   "outputs": [],
   "source": [
    "yMax = resampled_data.max()['y']\n",
    "yMin = resampled_data.min()['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m58z2N_b-VVd",
    "outputId": "42191aff-3c9e-4afb-f69f-7b2c763e90d9"
   },
   "outputs": [],
   "source": [
    "print('OPM range for training: [ %.2f, %.2f]'%(yMin, yMax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalize the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZ_U06RFTFWb"
   },
   "outputs": [],
   "source": [
    "resampled_data['y']=(resampled_data['y'] - yMin )/( yMax - yMin )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x-_vUJfh7VSg"
   },
   "outputs": [],
   "source": [
    "resampled_data_test['y'] = (resampled_data_test['y'] - yMin) / (yMax - yMin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``pred_next``: time window to predict (in mins)<br />\n",
    "``last_n``: time window used to predict  ```ped_next```<sup>th</sup> mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_CdpqPEd1OU"
   },
   "outputs": [],
   "source": [
    "last_n = 120\n",
    "pred_next = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Make feature set for training and testing purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_train,names_train = series_to_supervised(resampled_data, n_in = (last_n+pred_next) ,n_out= 1,target_label = 'y')\n",
    "cols_test,names_test = series_to_supervised(resampled_data_test, n_in = (last_n+pred_next) ,n_out= 1,target_label = 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "795j7DVkAfRT",
    "outputId": "25e3a65f-d055-4e7b-a869-9a9e86c0a92c"
   },
   "outputs": [],
   "source": [
    "# print(names_test)\n",
    "test_feat = pd.concat(cols_test,axis  = 1 )\n",
    "test_feat.columns = names_test\n",
    "train_feat = pd.concat(cols_train,axis  = 1 )\n",
    "train_feat.columns = names_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u56LQ8zBFTJV"
   },
   "outputs": [],
   "source": [
    "reframed_data_test = pd.concat([resampled_data_test, test_feat ],axis = 1 ).drop(columns = ['y'] ).dropna()\n",
    "reframed_data = pd.concat([resampled_data, train_feat ],axis = 1 ).drop(columns = ['y'] ).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qdDxjFqQK0_8"
   },
   "outputs": [],
   "source": [
    "# print(reframed_data_test.head())\n",
    "test_date = reframed_data_test.reset_index()[['dt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_to_predict = list(test_date['dt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### split Test and Train Data into input and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LmdRrI0_K6F8"
   },
   "outputs": [],
   "source": [
    "test = reframed_data_test.values\n",
    "test_X,test_y = test[:,:-pred_next],test[:,-1]\n",
    "test_X = test_X.reshape((test_X.shape[0],1,test_X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "i9mtZxZgSlVk",
    "outputId": "21401c98-9ac4-4a84-d436-0097df438fb3"
   },
   "outputs": [],
   "source": [
    "values = reframed_data.values\n",
    "train_index = len(values) # Consume the entire training data\n",
    "train = values\n",
    "train_X, train_y = train[:, :-pred_next], train[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape) \n",
    "# We reshaped the input into the 3D format as expected by LSTMs, namely [samples, timesteps, features]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3G8WxN667Lw"
   },
   "outputs": [],
   "source": [
    "train_ds =  reframed_data[:train_index].reset_index()\n",
    "test_ds  =  test_data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate the model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rOuzzuPXSuwl"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(rate = 0.22))\n",
    "model.add(LSTM(80))\n",
    "model.add(Dropout(rate = 0.12))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "2pLXlTeoG1Ss",
    "outputId": "e8c3cc20-a6b1-4d48-b89f-c6ecd7249d8c"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZAqiSBky-aO"
   },
   "outputs": [],
   "source": [
    "filepath=\"./dataset/weights-improvement-{epoch:02d}-{val_loss:.7f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model using the training dataset <br />\n",
    "Should be ignored if planning to load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_X, train_y, epochs=30, batch_size=120,validation_data=(test_X, test_y),callbacks=callbacks_list, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternatively one can save the entire session using dill\n",
    "[https://dill.readthedocs.io/en/latest/dill.html#dill._dill.dump_session]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Testing MSE  vs Epoch Numbers\n",
    "<br /> Should be ignored if planning to load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2352
    },
    "colab_type": "code",
    "id": "D9Z7qlm5y8XO",
    "outputId": "cdf502a8-68c7-4315-e4ab-2c02f003ae15"
   },
   "outputs": [],
   "source": [
    "# #summarize history for Normalised MSE Loss \n",
    "plt.grid()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Should not be executed if using ```model.fit```\n",
    "``load_model_file`` : File name where the model was stored(``.hdf5`` file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_model_file = 'change_this___with_the_model_file_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model( load_model_file )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the OPM using testing data and Calculate Errors\n",
    "``rmse`` : Root-Mean-Squared Error\n",
    "``mape`` : Mean-Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "h-t7UvCVSzCl",
    "outputId": "6632f2ac-106c-4054-82d2-daa8586388bf"
   },
   "outputs": [],
   "source": [
    "#load_path = './dataset/weights-improvement-04-0.00.hdf5'\n",
    "# model.load_weights(load_path) # UNCOMMENT to load the model from the file\n",
    "yhat = model.predict(test_X, verbose=0)\n",
    "rmse = np.sqrt(mean_squared_error(test_y, yhat))\n",
    "metric_df = pd.DataFrame({'y':test_y,'yhat':yhat[:,0]})\n",
    "metric_df = metric_df[ metric_df['y'] != 0 ] # can drop zero values (due to system crash)\n",
    "c_y = np.asarray(metric_df.y)*(yMax-yMin) + yMin\n",
    "c_yhat = np.asarray(metric_df.yhat)*(yMax-yMin) + yMin\n",
    "mape  = np.mean(np.abs(c_y-c_yhat)/c_y)*100\n",
    "print('Test RMSE: %.3f' % (rmse*(yMax-yMin)+yMin))\n",
    "print('Test MAPE: %.3f'% mape)\n",
    "print('Accuracy on Testing Dataset: %.3f'%(100-mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U26YMhmcuKMJ",
    "outputId": "d1bb4467-ceb8-47b4-d22f-3de3820d6232"
   },
   "outputs": [],
   "source": [
    "# # UNCOMMENT to check the training-related accuracy and errors\n",
    "# yhat_train = model.predict(train_X, verbose=0)\n",
    "# rmse_train = np.sqrt(mean_squared_error(train_y, yhat_train))\n",
    "# metric_df_train = pd.DataFrame({'y':train_y,'yhat':yhat_train[:,0]})\n",
    "# metric_df_train = metric_df_train[ metric_df_train['y'] != 0 ] # can drop zero values (due to system crash)\n",
    "# c_y_train = np.asarray(metric_df_train.y)*(yMax-yMin) + yMin\n",
    "# c_yhat_train = np.asarray(metric_df_train.yhat)*(yMax-yMin) + yMin\n",
    "# mape_train  = np.mean(np.abs(c_y_train-c_yhat_train)/c_y_train)*100\n",
    "# print('Train RMSE: %.3f' % (rmse_train*(yMax-yMin)+yMin))\n",
    "# print('Train MAPE: %.3f'% mape_train)\n",
    "# print('Accuracy on Training Dataset: %.3f'%(100-mape_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Denormalize the Outputs by LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9YUitjg1yB-"
   },
   "outputs": [],
   "source": [
    "# # UNCOMMENT to denormalize the predictions on the training dataset\n",
    "# yhat_train = yhat_train*(yMax - yMin) + yMin\n",
    "yhat = yhat*(yMax - yMin) + yMin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "4QwCsjwB2VFg",
    "outputId": "cdf0f6cf-6812-4284-de21-b0615daaaea0"
   },
   "outputs": [],
   "source": [
    "# dill.load_session('/content/drive/My Drive/Colab Notebooks/sessions/lstm_80_20_entire_data.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "PK99slvRHJns",
    "outputId": "e01bb848-c459-4938-ac3a-d4403b17fbfe"
   },
   "outputs": [],
   "source": [
    "# plt.plot()\n",
    "critical_start = datetime(2019,5,26,12,0,0)\n",
    "critical_end =  datetime(2019,5,26,22,59)\n",
    "holiday_start = datetime(2019,5,27,0,0,0)\n",
    "holiday_end =  datetime(2019,5,27,23,59)\n",
    "\n",
    "holiday_range = pd.date_range(start = holiday_start, end = holiday_end, freq = 'T')\n",
    "# print(pd.to(holiday_range.astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hCodICRSJcIf",
    "outputId": "289160a2-68f2-4a93-984c-be44ef35cfc9"
   },
   "outputs": [],
   "source": [
    "# !pip install mpld3\n",
    "%matplotlib notebook\n",
    "import mpld3\n",
    "mpld3.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "t9p3CzQIIJm9",
    "outputId": "ec0e05ff-a3fa-492f-bbd2-81c82c54e34e"
   },
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.plot(test_date, np.asarray(week2['Value']),'y',label = '2w' )\n",
    "plt.plot(test_date, np.asarray(week1['Value']),'r',label = '1w' )\n",
    "plt.plot(test_date,test_y*(yMax-yMin) + yMin,'b', label = 'current')\n",
    "\n",
    "plt.plot(test_date, yhat[:,0],'#00ffff',label = 'lstm')\n",
    "# plt.axvspan(xmin = critical_start, xmax = critical_end ,alpha=0.3,color = 'g', label = 'Zone of Concern')\n",
    "# plt.axvspan(xmin = holiday_start, xmax = holiday_end ,alpha=0.2,color = 'r', label = 'Holiday')\n",
    "plt.title('Using last:%d min to predict next %d mins'%(last_n, pred_next))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aWudcvE8OAhV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "time series",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
